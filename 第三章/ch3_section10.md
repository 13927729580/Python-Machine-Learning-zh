# 构建一棵决策树

决策树通过将特征空间分割为矩形，所以其决策界很复杂。但是要知道过大的树深度会导致过拟合，所以决策界并不是越复杂越好。我们调用sklearn，使用熵作为度量，训练一颗最大深度为3的决策树。还有一点，**对于决策树算法来说，特征缩放并不是必须的**。代码如下：





![](https://ooo.0o0.ooo/2016/06/21/576a009aef9dd.png)


执行上面的代码，我们得到如下结果，决策界和坐标轴平行：

![](https://ooo.0o0.ooo/2016/06/21/576a00c983f06.png)


sklearn的一大优点是可以将训练好的决策树模型输出，保存在.dot文件，我们可以利用GraphViz对其可视化。

先调用sklearn中export_graphviz将树模型导出:


![](https://ooo.0o0.ooo/2016/06/21/576a01910635d.png)

然后利用GraphViz程序将tree.dot转为PNG图片:

![](https://ooo.0o0.ooo/2016/06/21/576a01c465e7f.png)



现在我们可以查看决策树在构建树时的过程：根节点105个样本，使用 petal_width <=0.75分割为两个子节点。经过第一个分割，我们可以发现左节点中样本都是同一类型，所以停止此节点的分割，右节点继续分割，注意一点，**在构建决策树时两个特征各使用了两次**。







